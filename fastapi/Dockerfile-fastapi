# Use an NVIDIA CUDA base image
FROM ubuntu:latest

# Install Python and pip
RUN apt-get update && \
    apt-get install -y python3-pyaudio && \
    apt-get install -y python3-dev build-essential && \
    apt-get install -y mpg321 && \
    apt install ffmpeg -y && \
    apt-get install --no-install-recommends -y git vim build-essential python3-dev python3-venv python3-pip && \
    rm -rf /var/lib/apt/lists/*

# Set the working directory in the container
WORKDIR /app

# Copy the FastAPI application files into the container at /app
COPY api_server.py /app/
COPY requirements.txt /app/
COPY install_server.sh /app/

ENV PULSE_SERVER="/mnt/wslg/PulseServer"

# Install dependencies required for downloading and installing Miniforge
RUN apt-get update && apt-get install -y wget && \
    apt-get install -y pulseaudio && \
    apt-get install -y alsa-utils && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Setup app
RUN ./install_server.sh

# # Install any needed packages specified in requirements.txt
# RUN pip3 install -r requirements.txt

# # Force llama_cpp_cuda
# # Set the environment variable for CMAKE_ARGS
# ENV CMAKE_ARGS="-DLLAMA_CUBLAS=on"

# # Install llama-cpp-python with specific CMAKE_ARGS
# RUN pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir

# Expose the port the app runs on
EXPOSE 8000

# Set PATH to include Conda
ENV PATH="/opt/conda/bin:$PATH"
ENV CUDA_HOME=/usr/local/cuda-12.1
ENV LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64

# Run the application
CMD ["/bin/bash", "-c", "source activate fastapi-server && python api_server.py"]
