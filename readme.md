Certainly, here's the addition of the screenshots section and a placeholder for the flowchart:

# VoiceAI whisper-llm-gtts

## Overview

VoiceAI integrates the power of Text-to-Speech (TTS), Speech-to-Text (STT), and Local Language Model (LLM) technologies. This advanced AI application enables seamless conversion of text to speech, transcription of audio to text, and interaction with a local language model through an intuitive interface.

## Table of Contents

- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
  - [Environment Setup](#environment-setup)
  - [Running the App](#running-the-app)
- [Dockerization](#dockerization)
- [Screenshots](#screenshots)
- [System Flowchart](#system-flowchart)

## Getting Started

### Prerequisites

Ensure you have the following before proceeding with the installation:

- Python 3.10 or higher
- A GPU for running LLM + Whisper efficiently
- Docker for containerization

### Installation

Clone the VoiceAI repository and install the necessary dependencies:

```bash
git clone https://github.com/yourusername/VoiceAI.git
cd VoiceAI
pip install -r requirements_merged.txt
```

## Usage

VoiceAI provides robust audio and language processing features:

### Environment Setup

For a conventional setup using `venv` or `conda`, launch `run.sh` located at the root of the project. This script automates the environment creation, dependency installation, and starts both the server and frontend:

```bash
bash run.sh
```

### Running the App

To use VoiceAI, you need to open two terminals:

- In the first terminal, launch FastAPI:

  ```bash
  python fastapi/api_server.py
  ```

- In the second terminal, start the Streamlit frontend:

  ```bash
  streamlit run streamlit_app/run app.py
  ```

## Dockerization

The optimal way to run VoiceAI with Docker is using Docker Compose:

```bash
docker-compose up --build
```

Run this command in the root of the project to build and start the containers.

## Screenshots

*Here you can include a series of images demonstrating the application in action. Show the user interface, examples of audio transcription, and responses generated by the LLM.*

![Screenshot 1 Description](ressources/ask_with_text.png)
![Screenshot 2 Description](ressources/tab_record_audio.png)
![Screenshot 3 Description](ressources/tab_upload_file.png)

## System Flowchart

@startuml
actor User
entity "Whisper\n(Speech-to-Text)" as Whisper
entity "LLM\n(Local Language Model)" as LLM
entity "TTS\n(Text-to-Speech)" as TTS

User -> Whisper : speaks into microphone
Whisper -> LLM : transcribed text
LLM -> TTS : processed response
TTS -> User : speaks response
@enduml


![System Flowchart](ressources/uml_whisper.png)


## Technologies & Skills

VoiceAI is built using a variety of technologies and demonstrates proficiency in numerous skills:

### Libraries

- **FastAPI**: An innovative web framework for building APIs with Python based on standard Python type hints.
- **Streamlit**: An open-source app framework for Machine Learning and Data Science teams.
- **Whisper**: OpenAI's general-purpose speech recognition model for transcribing speech.
- **gTTS (Google Text-to-Speech)**: A Python library and CLI tool to interface with Google Translate's text-to-speech API.
- **PyTorch**: An open-source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing.

### Skills

- **API Development**: Designing and creating robust APIs for efficient communication between different software components.
- **Machine Learning**: Applying models to perform tasks such as speech recognition and language understanding.
- **Full Stack Development**: Implementing both backend and frontend components of the application.
- **Dockerization**: Containerizing applications for ease of deployment and scalability.
- **Audio Processing**: Handling and processing audio data for transcription and speech synthesis.

### Tools

- **Docker & Docker Compose**: For containerizing the application and managing multi-container Docker applications.
- **Git**: For version control and source code management.
- **Uvicorn**: An ASGI server for Python, used to run FastAPI applications.

